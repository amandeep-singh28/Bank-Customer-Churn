# ðŸ’¼ðŸ“‰ Bank-Customer-Churn-Prediction-and-ML-Model-Comparison

A complete churn prediction project developed using **Python and Scikit-Learn**, involving data preprocessing, feature encoding, scaling, and multiple imbalance handling techniques such as **SMOTE, ADASYN, undersampling, and class weighting**. The project applies various machine learning algorithms, including logistic models, tree-based methods, and boosting techniques such as **AdaBoost, Gradient Boosting, and XGBoost**, while carefully addressing and preventing data leakage using proper trainâ€“test split pipelines. Model performance is evaluated using metrics like ROC-AUC, PR-AUC, Recall, and F1-Score to enable a structured comparison and determine the most effective approach for customer churn prediction.

---

## ðŸ§© **1. Project Workflow Overview**

This project follows an industry-standard ML pipeline:

- **Python (Pandas / Numpy)** â†’ Data cleaning & preprocessing  
- **Data Leakage Prevention** â†’ Ensuring transformations & resampling are applied only on training data using pipelines  
- **Imbalance Handling** â†’ SMOTE, ADASYN, Undersampling, Class Weights  
- **Model Training** â†’ Trained 6 different ML algorithms + sampling variants  
- **Model Evaluation** â†’ Recall, F1, ROC-AUC, PR-AUC metrics  
- **Final Model Selection** â†’ XGBoost with highest churn detection capability  

---

## âœˆï¸ **2. Detailed Project Explanation**

This section describes the end-to-end workflow followed in this project, from raw data to final model comparison.

### ðŸ¥‡ (i). Importing and Understanding the Dataset
- Loaded the bank customer dataset containing features such as:
  - Customer demographics (Age, Gender, Geography)
  - Account information (Balance, Tenure, Number of Products, HasCrCard, IsActiveMember)
  - Financial details (CreditScore, EstimatedSalary)
  - Target variable: **Exited** (1 = churn, 0 = not churn)
- Performed basic checks:
  - Shape of the dataset  
  - Data types of each column  
  - Presence of null values and duplicates

---

### ðŸ§¼ (ii). Data Cleaning

- Handled missing values:
  - Replaced null values in the `Surname` column using the mode (most frequent value).
  - Replaced missing values in the `Age` column using the mean of the age distribution.

- Standardized inconsistent categorical values:
  - Converted `'FRA'` and `'French'` entries in the `Geography` column to `'France'` for consistency.

- Cleaned numeric fields:
  - Removed the `'â‚¬'` symbol from the `EstimatedSalary` column to ensure numerical formatting.















## ðŸ§¹ **2. Data Cleaning & Preparation (Python)**

### ðŸ”§ **Key Cleaning Operations**
- Removed duplicates  
- Handled missing values  
- Label encoding & one-hot encoding for categorical columns  
- Numerical feature scaling using StandardScaler  
- Saved intermediate cleaned datasets for reproducibility  

### ðŸ“Š **Final Features Used**
| Feature | Description |
|---------|-------------|
| CreditScore | Customer credit rating |
| Age | Customer age |
| Tenure | Years with bank |
| Balance | Current account balance |
| NumOfProducts | Number of bank products used |
| HasCrCard | Credit card status |
| IsActiveMember | Customer engagement |
| Gender | Male/Female |
| Geography | Country |
| EstimatedSalary | Income level |

---

## âš–ï¸ **3. Handling Class Imbalance**

Dataset distribution:  
- **80%** â€” Not churn (class 0)  
- **20%** â€” Churn (class 1)  

To avoid bias toward the majority class, applied:

- Random Undersampling  
- SMOTE  
- ADASYN  
- Class Weights  
- XGBoost scale_pos_weight  

Objective: improve recall of churners.

---

## ðŸ§  **4. Machine Learning Models Used**

Implemented and compared:

- Logistic Regression  
- Decision Tree  
- Random Forest  
- Gradient Boosting  
- AdaBoost  
- **XGBoost (best)**  

Each with:
- Base model  
- SMOTE version  
- ADASYN version  
- Undersampling  
- Class Weighting  

Hyperparameter tuning applied using:
- GridSearchCV(cv=5, scoring=[precision, recall, f1], refit='recall')
- This ensures the models are optimized to **maximize recall for churn detection**, since retaining customers is more important than false positives.

---

## ðŸ“Š **5. Model Performance**

### ðŸ† Final Best Model: **XGBoost**

| Metric | Score |
|--------|-------|
| Recall (Churn class) | **76%** |
| ROC-AUC | **88%** |
| PR-AUC | **71%** |

âž¡ Selected as final model due to best performance in identifying churners while maintaining strong overall ranking ability.

---

## ðŸ“ **6. Dataset Description**

Includes customer details and churn indicator:

- Age  
- CreditScore  
- Tenure  
- Balance  
- Estimated Salary  
- Geography  
- Gender  
- Number of products  
- Active membership  
- Has/Doesnâ€™t have credit card  
- Target column: `Exited` (1 = churn, 0 = stay)

---

## ðŸ’¡ **7. Key Insights From Analysis**

âœ” Customers with low activity & engagement churn more  
âœ” Higher number of products â†’ reduced churn  
âœ” Salary alone is not a strong predictor  
âœ” Certain geographical regions have more churn tendency  
âœ” Middle-aged customers show higher churn patterns  

---

## ðŸš€ **8. Future Enhancements**

- Add SHAP or LIME for interpretability  
- Create Streamlit UI for model demo  
- Deploy model via API endpoint  
- Continuously train model on fresh data  
- Add temporal behaviour features (e.g., monthly transactions)  

---

> ðŸ™Œ **Built with strong ML methodology, fair sampling strategies, and statistical model evaluation to support business-driven churn reduction strategies.**

---

### ðŸ”— **Connect**

For collaboration or suggestions â€” feel free to reach out!



